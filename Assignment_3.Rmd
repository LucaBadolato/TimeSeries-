---
title: "20236 Time Series Analysis - Assignment 3"
author:
- Simone Arrigoni (1794692)
- Luca Badolato (3086040)
- Simone Valle (3088281)
subtitle: "Bocconi University"
date: March 16, 2020
output: 
  pdf_document
header-includes:
  \usepackage[utf8]{inputenc}
  \usepackage{setspace}
  \usepackage{algpseudocode}
  \usepackage{algorithm}
  \usepackage{bm}
  \usepackage{amsmath}
  \usepackage{amssymb}
  \usepackage{graphicx}
  \usepackage{subfig}
  \usepackage{booktabs, caption}
  \usepackage{array}
  \usepackage{threeparttable}
  \usepackage{listings}
  \usepackage{physics}
  \usepackage{float}
  \floatplacement{figure}{H}
  \DeclareMathOperator*{\E}{\mathbb{E}}
  \DeclareMathOperator*{\Ec}{\mathbb{E}_t}
  \DeclareMathOperator*{\V}{\mathbb{V}}
  \DeclareMathOperator*{\Vc}{\mathbb{V}_t}
---

```{r, include=FALSE}
knitr::opts_chunk$set(fig.pos="H")
# Load useful packages
library(utf8)
library(labeling)
library(rmarkdown)
library(knitr)
library(tseries)
library(dlm)
library(ggplot2)
library(tidyr)
```

\section{Exercise 1}
Let's consider a discrete time stochastic process $(Y_{t})_{t\geq0}$ with $Y_{t} \in \{1,2,...,K\}$ and define $p_{0}(\cdot)$ the \textit{initial distribution} of $Y_{t}$.
\begin{itemize}
\item $Y_{t}$ is a Markov chain, (or \textit{Markov process}), if $Y_{0} \sim p_{0}(\cdot)$ and $Y_{t}$ depends on the past observations through $Y_{t-1}$ and only through it. In other words, if $Y_{t}$ is conditionally independent on $(Y_{0}, ..., Y_{t-2})$ given $Y_{t-1}$.
\item The set $\mathcal{Y}$ of all possible values taken by the process $Y_{t}$ is defined \textit{State Space} of Markov process.
\item An example of a Markov chain is that of independent trials, which is a useful model for categorical time series.
Other examples are the simple random walk and the continuous random walk among discrete time processes or Brownian motions and Poisson point processes among continuous time processes.
\end{itemize}

\section{Exercise 2}
Let's consider a homogeneous Markov chain $(Y_{t})_{t\geq0}$ with finite state-space $\mathcal{Y}=\{1,2,...,K\}$.
\begin{itemize}
\item The initial distribution $p_{0}$ is the probability distribution of the process at time $t=0$, i.e. $Y_{0} \sim p_{0}$.
The transition matrix $\textbf{P}$ collects the \textit{transition probabilities} $p_{ij}=P(Y_{t}=j|Y_{t-1}=i)$ for every $t\geq0$ and for every $i,j \in \mathcal{Y}$, i.e. the probabilities of $Y$ of moving from state $i$ at time $t-1$ to state $j$ at time $t$.
For non-homogeneous Markov chains the transition matrix can be different for any $t$, i.e. $\textbf{P}_{t_{1}} \ne \textbf{P}_{t_{2}}$.
\item Suppose that $K=3$, the conditional distribution of $Y_2=1$ given $y_1$ and $y_2$ is:
\begin{equation*}
P(Y_{2}=1 \; | \; Y_{1}=2, Y_{0}=2) = P(Y_{2}=1 \; | \; Y_{1}=2) = p_{2,1}
\end{equation*}
\item Also, the joint probability distribution $P(\underline{\mathbf{Y}}=\underline{\mathbf{y}})$ is defined as:
\begin{equation*}
\begin{split}
P(\underline{\mathbf{Y}}=\underline{\mathbf{y}})\\
=P(Y_{0}&=2, Y_{1}=2, Y_{3}=1, Y_{4}=2, Y_{5}=2, Y_{6}=2, Y_{7}=1, Y_{8}=3) \\
= & P(Y_{1}=2 \; | \; Y_{0}=2) \; P(Y_{3}=1 \; | \; Y_{1}=2, Y_{0}=2) \; P(Y_{4}=2 \; | \; Y_{3}=1, Y_{1}=2, Y_{0}=2) \\ & \; P(Y_{5}=2 \; | \; Y_{4}=2, Y_{3}=1,  Y_{1}=2, Y_{0}=2) \; P(Y_{6}=2 \; | \; Y_{5}=2, Y_{4}=2, Y_{3}=1, Y_{1}=2, Y_{0}=2) \\ & \; P(Y_{7}=1 \; | \; Y_{6}=2, Y_{5}=2, Y_{4}=2, Y_{3}=1, Y_{1}=2, Y_{0}=2) \\ & \; P(Y_{8}=3 \; | \; Y_{7}=1, Y_{6}=2, Y_{5}=2, Y_{4}=2, Y_{3}=1, Y_{1}=2, Y_{0}=2) \\
= & \; P(Y_{1}=2 \; | \; Y_{0}=2) \; P(Y_{3}=1 \; | \; Y_{1}=2) P(Y_{4}=2 \; | \; Y_{3}=1) \; P(Y_{5}=2 \; | \; Y_{4}=2) \\ & \; P(Y_{6}=2 \; | \; Y_{5}=2) \; P(Y_{7}=1 \; | \; Y_{6}=2) \; P(Y_{8}=3 \; | \; Y_{7}=1) \\
= & \; (p_{2,2})(p_{2,1})(p_{1,2})(p_{2,2})(p_{2,2})(p_{2,1})(p_{1,3}) \\
= & \; (p_{1,2})(p_{1,3})(p_{2,1}^{2})(p_{2,2}^{3})
\end{split}
\end{equation*}

\item This is the solution by S.A.
\begin{align*}
    P(\underline{\mathbf{Y}}=\underline{\mathbf{y}}) &= P(Y_{0}=2, Y_{1}=2, Y_{3}=1, Y_{4}=2, Y_{5}=2, Y_{6}=2, Y_{7}=1, Y_{8}=3)\\
    &= P_{y_0}(y_1) \; P_{y_1}(y_3) \; P_{y_3}(y_4) \; ... \; P_{y_7}(y_8)\\
    &= p_{2,2}\; \biggl[\sum_{j=1}^{3} P(T_{3}=1 \;|\; Y_{2}=j,Y_{1}=2)\biggr] \; p_{1,2}\ p_{2,2}\ p_{2,2}\ p_{2,1}\ p_{1,3}\\
    &= p_{1,2}\ p_{2,2}^2\ p_{2,2}\ p_{2,1}\ p_{1,3}\ (p_{1,2}\ p_{1,1} + p_{2,2}\ p_{2,1} + p_{2,3}\ p_{3,1})
\end{align*}
\end{itemize}


\section{Exercise 3}
We are now considering a simple random walk.
\begin{itemize}
\item The process $(Y_{t})_{t\geq0}$ is not stationary. Indeed, the variance is not constant and it explodes with increasing $t$

From the random walk equation $Y_t=Y_{t-1}+Z_t$, by recursively substituting for each $t$, we obtain,
\begin{align*}
    Y_t = Y_{t-1}+Z_t =Y_{t-2}+Z_{t-1}+Z_t=...=Y_0+\sum_{k=1}^{t}Z_k
\end{align*}

Since the random gain is distributed as
\begin{align*}
\begin{split}
    Z_t=
    \begin{cases}
      +1, & \text{w.p.}\ p \\
      -1, & \text{w.p.}\ (1-p)
    \end{cases}
    \quad \forall t
\end{split}
 \end{align*}
Hence, $\E[Z_t]=0$ and $\V[Z_t]=1$ for each $t$

Then, the unconditional first and second moments of $Y_t$ are
\begin{align*}
    \begin{split}
        \E[Y_t]=y_0+\sum_{k=1}^{t}\E[Z_k]=y_0 \; , \quad & \quad  \V[Y_t]=\sum_{k=1}^{t}\V[Z_k]=t
    \end{split}
\end{align*}
with $\V[Y_t]\rightarrow\infty$ as $t\rightarrow\infty$.
\item The process $(Y_{t})_{t\geq0}$ is a Markov chain, as it has the Markov property, namely $Y_{t}$ depends on the past observation only through $Y_{t-1}$. Indeed, conditionally on the trajectory $(y_{0}, Y_{1}=y_{1},...,Y_{t-1}=i)$, the probability law of the capital $Y_{t}$ at the next step does not depend on the entire trajectory but only on the position reached at time $t-1$, that is $Y_{t-1}=i$.
\end{itemize}

\section{Exercise 4}
Let's consider a continuous random walk:
\begin{equation*}
Y_{t}=Y_{t+1}+Z_{t} \qquad Z_{t} \overset{i.i.d.}{\sim} N(\mu,\sigma^{2}).
\end{equation*}
\begin{itemize}
\item The mean function $\mu(t)=\E[Y_t]$ is
\begin{align*}
    \mu(t)=\E[Y_t]=\E\biggl[y_0+\sum_{k=1}^{t}Z_k\biggr]=y_0+t\mu
\end{align*}

Similarly, the variance function $\sigma^2(t)=\V(Y_t)$ is
\begin{align*}
    \sigma^2(t)=\V[Y_t]=\V\biggl[y_0+\sum_{k=1}^{t}Z_k\biggr]=t\sigma^2
\end{align*}

The process $(Y_{t})_{t\geq0}$ is not weakly stationary because both the mean and variance functions shown above are not constant and diverge as time goes by.
\item The process $(Y_{t})_{t\geq0}$ satisfies the Markov property and is thus a Markov chain. Indeed, $Y_{t}$ depends on the past observation only through $Y_{t-1}$. Moreover, $Y_t$ is a sufficient statistic for the filtration $\mathcal{F}_{t-1}$
\item However, the process $(Y_t)$ is Integrated of order 1, implying by definition of integration that  $(R_{t})$ is, in fact, stationary.

Indeed,

\begin{align*}
    R_t:=Y_t - Y_{t-1}=Z_t \; , \quad Z_{t}\overset{i.i.d.}{\sim}N(\mu,\sigma^2) 
\end{align*}

Follows that the mean and variance function of $R_t$ are constant over time, that is
\begin{align*}
    \begin{split}
        \E[R_t]=\E[Z_t]=\mu \; , \quad  \V[R_t]=\V[Z_t]=\sigma^2 \quad \forall t
    \end{split}
\end{align*}
\end{itemize}

\section{Exercise 5}
\begin{itemize}
\item Knowing the state-space, the initial value and the transition matrix, the probability that $Y_{2}=2$ can be obtained as follows:
\begin{equation*}
\begin{split}
P(Y_{2}=2)
& = \sum_{i=1}^{3} P(Y_{2}=2 \; | \; Y_{1}=i) \; P(Y_{1}=i \; | \; Y_{0}=1) \\
& = \sum_{i=1}^{3} p_{1,i} \; p_{i,2} = p_{1,1} \; p_{1,2} + p_{1,2} \; p_{2,2} + p_{1,3} \; p_{3,2} \\
& = 0.6 \cdot 0.4 + 0.4 \cdot 0.7 + 0 \cdot 0.1 = 0.52
\end{split}
\end{equation*}
\item We also have that:
\begin{equation*}
\begin{split}
P(Y_{1}=1 \; | \; Y_{2}=2, Y_{0}=1) 
& = \frac{P(Y_{2}=2 \; | \; Y_{1}=1, Y_{0}=1) \; P(Y_{1}=1 \; | \; Y_{0}=1)}{P(Y_{2}=2)} \\
& = \frac{P(Y_{2}=2 \; | \; Y_{1}=1) \; P(Y_{1}=1 \; | \; Y_{0}=1)}{P(Y_{2}=2)} \\
& = \frac{p_{1,1} \; p_{1,2}}{P(Y_{2}=2)} = \frac{0.6 \cdot 0.4}{0.52} = 0.4615
\end{split}
\end{equation*}
\end{itemize}

\section{Exercise 6}
\begin{itemize}
\item The state-space of the given Markov chain is $\mathcal{Y}=\{1,2,3\}$.
\item The marginal probability distribution of $Y_{2}$, given the starting value $Y_{0}=1$ is:
\begin{equation*}
\begin{split}
P(Y_{2}=i \; | \; Y_{0}=1)
& =
\begin{cases}
\sum_{j=1}^{3} P(Y_{2}=1 \; | \; Y_{1}=j) \; P(Y_{1}=j \; | \; Y_{0}=1) \qquad \text{if $i=1$} \\
\sum_{j=1}^{3} P(Y_{2}=2 \; | \; Y_{1}=j) \; P(Y_{1}=j \; | \; Y_{0}=1) \qquad \text{if $i=2$} \\
\sum_{j=1}^{3} P(Y_{2}=3 \; | \; Y_{1}=j) \; P(Y_{1}=j \; | \; Y_{0}=1) \qquad \text{if $i=3$}
\end{cases} \\
& = 
\begin{cases}
0.48 \qquad \text{if $i=1$} \\
0.48 \qquad \text{if $i=2$} \\
0.04 \qquad \text{if $i=3$}
\end{cases}
\end{split}
\end{equation*}
\end{itemize}

\section{Exercise 7}
\begin{itemize}
\item We have that:
\begin{equation*}
P(Y_{1}=2, Y_{2}=1 \; | \; Y_{0}=1) = 0.4 \cdot 0 = 0
\end{equation*}
\item The above Markov chain is irreducible... because...
\end{itemize}
f
\section{Exercise 8}
Let's consider a Markov chain $(Y_{t})_{t \geq 0}$ with finite state-space $\mathcal{Y}$. Our aim is to study the probability distribution of $Y_n$, given the initial state $Y_0 = j$, that is $P(Y_n = k | Y_0 = j)$ for $K = 1, ..., N$, the possible states. 

In general the random variables $Y_n$ are not identically distributed, since the distribution of $Y_n$ varies with $n$. However, if the Markov chain is eergotic, the conditional distribution of $Y_n$ given the initial state $j$ converge to the limit distribution $P ^ {\ast} (.)$. This result is provided by the Ergotic theorem, a fundamental result in Markov chain theory: 
\medskip


**Th** Let $(Y_{t})_{t \geq 0}$ be an \textbf{irriducible} and \textbf{aperiodic} Markov chain with finite state space $\textit{Y}\{ 1, ..., N \}$. Then:


$(i)$ The conditional distribution $P(Y_n = . | Y_0 = j)$ converges to a limit distribution $p ^ {\ast} (.)$, independent of $j$. More specifically, for any $j$ and $k$ :

\begin{center}
$\lim_{n \to \inf} P(Y_n = k | Y_0 = j) = p ^ {\ast} (k) > 0$
\end{center}


where $p ^ {\ast} (1), ... ,p ^ {\ast} (N)$ is a probability distribution: $p ^ {\ast} (k) > 0 \forall k \in \textit{Y}$ and $\sum_{k \in \textit{Y}} p^{\ast} = 1$.

$(ii)$ Moreover, the $p^{\ast} (k)$ satisfy
\begin{center}
$p^{\ast} (k) = \sum_{i \in \textit{Y}} p^{\ast} (i) p_{i, k}.$
\end{center}


\bigskip

The required conditions are irreducibility and aperiodicity: 

A state $j$ is *periodic* with period $t$ if a return to state $j$ is possible only in $7, 2t, 3t ...$ steps. 

A Markov chain is *irreducible* if  there are no closed set, that is, for every set $C$ of states no one-step transition in possible from any state inside $C$ to any outside $C$, i.e. $p_{j,k} = 0$ if $j \in C$ and $k \notin C$.


\section{Exercise 9}
\begin{itemize}

\item Given the assumption of homogeneity, it is possible to sum all the counts, obtaining the following matrix of transition counts:

\begin{center}
 \begin{tabular}{|c|c|c|c|c|}
\hline 
 & 1 & 2 & 3 &  \\ 
\hline 
1 & 105 & 10 & 15 & 130 \\ 
\hline 
2 & 40 & 55 & 25 & 120 \\ 
\hline 
3 & 25 & 55 & 70 & 150 \\ 
\hline 
\end{tabular} 
\end{center}

The MLE of $p_{3,1}$, given by $\hat{p}_{i,j} = \frac{n_{i,j}}{n_{i,+}}$, is:
\begin{equation*}
\hat{p}_{3,1}=\frac{25}{150}=\frac{1}{6}=0.1\overline{6}.
\end{equation*}

\item The asymptotic confidence interval of level 0.95 for $p_{3,1}$ is:
\begin{equation*}
\begin{split}
\bigg[\hat{p}_{3,1}-1.96\sqrt{\frac{\hat{p}_{3,1}(1-\hat{p}_{3,1})}{n_{3,+}}}\text{;} \; \hat{p}_{3,1}+1.96\sqrt{\frac{\hat{p}_{3,1}(1-\hat{p}_{3,1})}{n_{3,+}}}\bigg]
& = \bigg[\frac{1}{6}-1.96\sqrt{\frac{\frac{1}{6}\cdot\frac{5}{6}}{150}}\text{;} \; \frac{1}{6}+1.96\sqrt{\frac{\frac{1}{6}\cdot\frac{5}{6}}{150}}\bigg] \\
& = \big[0.16667-1.96 \cdot 0.05270 \text{;} \; 0.16667+1.96 \cdot 0.05270\big] \\
& = \big[0.063378 \text{;} \; 0.269962\big]
\end{split}
\end{equation*}

\item Relaxing the homogeneity assumption for the Markov chain, the MLEs of $p_{3,1}(t)$ for $t=1,2$ are:
\begin{equation*}
\begin{split}
& \hat{p}_{3,1}(1)=\frac{10}{55}=0.\overline{18} \\
& \hat{p}_{3,1}(2)=\frac{10}{40}=0.25
\end{split}
\end{equation*}

\end{itemize}


\section{Exercise 10}

\begin{itemize}

\item First, we estimate the transition matrix $P$ based on the data, that is: 

\begin{center}
 \begin{tabular}{|c|c|c|c|}
\hline 
 & 1 & 2 & 3 \\ 
\hline 
1 & 30/120 & 20/120 & 40/120  \\ 
\hline 
2 & 20/120 & 80/120 & 20/120  \\ 
\hline 
3 & 20/160 & 120/160 & 20/160  \\ 
\hline 
\end{tabular} 
\end{center}

simplifying, we obtain: 

\begin{center}
 \begin{tabular}{|c|c|c|c|}
\hline 
 & 1 & 2 & 3 \\ 
\hline 
1 & 0.5 & $0.1\overline{6}$ & $0.3\overline{3}$  \\ 
\hline 
2 & $0.1\overline{6}$ & $0.6\overline{6}$ & $0.1\overline{6}$  \\ 
\hline 
3 & 0.125 & 0.75 & 0.125  \\ 
\hline 
\end{tabular} 
\end{center}

Hence, we have that:

$P(Y_{1,1}=1, Y_{1,2}=3, Y_{1,3}=3, Y_{1,4}=2 \; | \; Y_{1,0}=1; \text{\textbf{P}}) =$

$P(Y_{1,1}=1 \; | \; Y_{1,0}=1; \text{\textbf{P}}) P(Y_{1,2}=3 \; | \; Y_{1,1}=1; \text{\textbf{P}}) P(Y_{1,3}=1 \; | \; Y_{1,2}=3; \text{\textbf{P}}) P(Y_{1,4}=2 \; | \; Y_{1,3}=3; \text{\textbf{P}})=$ 

$= 0.5 \cdot 0.3\overline{3} \cdot 0.125 \cdot 0.75 = 0.01547$ . 

\item Assuming that the initial values $y_{k,0}$ are fixed, the likelihood is: 
\medskip
\begin{center}
$L((p_{i,j}); y_1 , ..., y_n, \textit{initial values}) =$

$=p(y_1 , ..., y_n; (p_{i,j}), \textit{initial values}) =$

$= \prod_{k=1}^{n} p(y_k ; (p_{i,j}))=$

$= \prod_{i=1}^{N} \prod_{j=1}^{N} p_{i,j}^{n_{i,j}}$. 
\medskip
\end{center}

To obtain the MLEs we have to mazimize this expression with respect to the $p_{i,j}$, with the constraint $p_{i,j} \geq 0$ and $\sum_{j=1}^{N} p_{i,j} = 1$. Being the likelihood previously obtained proportional to the product of multinomial distributions with parameters $n_{i, +}$ and $(p_{i,1}, ..., p_{i,N})$, the problem of finding the MLEs of the $p_{i,j}$ reduces to computing the MLEs for the probabilities $(p_{i,1}, ..., p_{i,N})$ of independent Multinomial distributions, which are: 

\begin{center}
$\hat{p}_{i,j} = \frac{n_{i,j}}{n_{i,+}}, \; \; \; \; j = 1, ..., N$
\end{center}
for $i = 1, ..., N$. 



\item The MLEs of $p_{i,j}$ are the ones computed before in the estimated transtion matrix P: 

\begin{center}
$P(Y_3 = 2 | Y_2 = 1) = 0.1\overline{6}$.
\end{center}

\item The asymptotic confidence interval of level 0.90 is :

\begin{center}
$\bigg[\hat{p}_{1,2}-1.65\sqrt{\frac{\hat{p}_{1,2}(1-\hat{p}_{1,2})}{n_{1,+}}}\text{;} \; \hat{p}_{1,2}+1.65\sqrt{\frac{\hat{p}_{1,2}(1-\hat{p}_{1,2})}{n_{1,+}}}\bigg]=$

$= \bigg[0.1\overline{6} -1.65\sqrt{\frac{0.1\overline{6}(1-0.1\overline{6})}{120}}\text{;} \; 0.1\overline{6}+1.65 \sqrt{\frac{0.1\overline{6}(1-0.1\overline{6})}{120}}\bigg]=$

$= \big[0.11083 \text{;} \; 0.22317\big]$
\end{center}

\end{itemize}.



