
---
title: "20236 Time Series Analysis - Alaska Pollution Dataset"
author:
- Simone Arrigoni (1794692)
- Luca Badolato (3086040)
- Simone Valle (3088281)
subtitle: "Bocconi University"
date: April, 2020
output: 
  pdf_document
header-includes:
  \usepackage[utf8]{inputenc}
  \usepackage{setspace}
  \usepackage{algpseudocode}
  \usepackage{algorithm}
  \usepackage{bm}
  \usepackage{amsmath}
  \usepackage{amssymb}
  \usepackage{graphicx}
  \usepackage{subfig}
  \usepackage{booktabs, caption}
  \usepackage{array}
  \usepackage{threeparttable}
  \usepackage{listings}
  \usepackage{physics}
  \usepackage{float}
  \floatplacement{figure}{H}
  \usepackage{color} %red, green, blue, yellow, cyan, magenta, black, white
  \definecolor{mygreen}{RGB}{28,172,0} % color values Red, Green, Blue
  \definecolor{mylilas}{RGB}{170,55,241}
  \DeclareMathOperator*{\E}{\mathbb{E}}
  \DeclareMathOperator*{\Ec}{\mathbb{E}_t}
---

```{r, include=FALSE}
# Load useful packages
library(utf8)
library(labeling)
library(rmarkdown)
library(httr)
library(knitr)
library(tseries)
library(scales)
library(dlm)
library(depmixS4)
library(tidyr)
library(tidyverse)
library(ggthemes)
library(magrittr)
library(latex2exp)
library(kableExtra)
library(ggpubr)
library(reshape2)
# Settings
knitr::opts_chunk$set(message = FALSE, 
                      warning = FALSE,
                      echo    = FALSE,
                      include = TRUE,
                      fig.pos = "H",
                      fig.align = "center")
```


We obtain the raw dataset from the website \textit{Kaggle} (https://www.kaggle.com/sogun3/uspollution).
It collects data for U.S. states about four main pollutants - Nitrogen Dioxide (\textit{NO2}), Sulphur Dioxide (\textit{SO2}), Carbon Monoxide (\textit{CO}) and Ozone (\textit{O3}) - for every day from 2000 to 2016 with four intraday observations. Importantly, this is an unbalanced panel since the sample periods differs among states.

```{r echo=FALSE}
# Import the dataset for all US states
raw_data <- read.csv("pollution_us_2000_2016.csv", sep = ",", header=T)
```

Given the relatively high frequency of the data and the high dimension of the dataset, we need to shrink it so as to extract more concise information which will allow us to perform our analysis.
For this reason we first aggregate data about pollutants for each state with weekly frequency.

```{r echo=FALSE}
## Preliminary analysis
# Partition the dataset to get data for all states
state_label<-unique(raw_data$State)
state_id<-length(state_label)
plotList <- list()
df_list<-list()

for (idx in 1:state_id){
  subsample <- raw_data[raw_data$State==state_label[idx],]  
  # Weekly CO, NO2, O3, SO2 in mean
  counter_w<-nrow(subsample)/28 %>% as.integer()
  
  matr<-matrix(NA,counter_w)
  weekly_CO_mean<-matrix(0,counter_w,1)
  weekly_O3_mean <-matrix(0,counter_w,1)
  weekly_NO2_mean<-matrix(0,counter_w,1)
  weekly_SO2_mean<-matrix(0,counter_w,1)
  
  for (k in 1:counter_w) {
    i=28*k
    j=k+(27*(k-1))
    weekly_CO_mean[k]<-mean(subsample$CO.Mean[i:j])
    weekly_O3_mean[k]<-mean(subsample$NO2.Mean[i:j]) 
    weekly_NO2_mean[k]<-mean(subsample$O3.Mean[i:j])
    weekly_SO2_mean[k]<-mean(subsample$SO2.Mean[i:j])
  }
  
  df<-data.frame(weekly_CO_mean,weekly_NO2_mean,weekly_O3_mean, weekly_SO2_mean)
  
  #create a matrix for each state with the 4 variables
  nam<-paste("variable_",state_label[idx],sep="")
  df_list[[idx]]<-df
  assign(nam, df)
  
}

```

```{r echo=FALSE}
# Attach a id number to each State
identifier<-data.frame(1:state_id, state_label)

# Remove mute variable from the local environmet
rm(i)
rm(idx)
rm(j)
rm(k)
rm(nam)
rm(weekly_CO_mean)
rm(weekly_NO2_mean)
rm(weekly_O3_mean)
rm(weekly_SO2_mean)

```

After a closer inspection to the aggregated data, we identified the series for Louisiana's pollutants as the one of main interest. Therefore, we procede providing a plot of such a time series.
Data span from 2000-01-01 to 2016-04-27, therefore some last observations get lost by construction in aggregating with weekly frequency.


```{r}

# Obtain a vector with the observation dates
days<- raw_data[raw_data$State=="Louisiana",9]
days<-unique(days)

```


Data span from 2000-01-01 to 2016-04-27, therefore some last observations get lost by construction in aggregating with weekly frequency.

```{r}
# Louisiana - Time series plot (Weekly)

n_weeks<-1:nrow(variable_Louisiana)

  W1<-ggplot(variable_Louisiana, aes(x=n_weeks, y=weekly_CO_mean))+geom_line()+ggtitle("Louisiana")+theme_classic2()
  W2<-ggplot(variable_Louisiana, aes(x=n_weeks, y=weekly_NO2_mean))+geom_line()+ggtitle("Louisiana")+theme_classic2()
  W3<-ggplot(variable_Louisiana, aes(x=n_weeks, y=weekly_O3_mean))+geom_line()+ggtitle("Louisiana")+theme_classic2()
  W4<-ggplot(variable_Louisiana, aes(x=n_weeks, y=weekly_SO2_mean))+geom_line()+ggtitle("Louisiana")+theme_classic2()
  
Louisiana_TSplot_W<-ggarrange(W1, W2, W3, W4, ncol = 2, nrow = 2)
Louisiana_TSplot_W
  
```

The chart shows a rather different behavior for the four series of interest. For this reason, we think this subsample will provide a good example for exploring several different statistical techniques.   

We conclude this preliminary steps by creating a new dataset storing data for Louisiana's pollutants with only weekly frequency, which will provide a basis for the core analysis of the project.

```{r}
# export the new dataset to CSV
louisiana_dataset<-data.frame(n_weeks, variable_Louisiana)

path_out = getwd()
write.csv(louisiana_dataset,paste(path_out,'/Louisiana_dataset.csv',sep = ''),row.names=FALSE)

```

The dataset is then made available in a public repository on GitHub.com
(https://raw.githubusercontent.com/SimoneArrigoni/US_pollution/master//Louisiana_dataset.csv)



